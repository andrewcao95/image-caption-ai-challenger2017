{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.display import Image\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:50000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:50000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt model_name InceptionResnetV2 height 299 width 299\n",
      "build graph for final one feature\n",
      "preprocessing_fn net_name inception_resnet_v2 height 299 width 299\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from deepiu.util.text_predictor import TextPredictor\n",
    "from deepiu.util.sim_predictor import SimPredictor\n",
    "from deepiu.util import text2ids\n",
    "import melt, gezi\n",
    "import numpy as np \n",
    "import traceback\n",
    "\n",
    "try:\n",
    "  import conf\n",
    "  from conf import TEXT_MAX_WORDS\n",
    "except Exception:\n",
    "  from deepiu.image_caption.conf import TEXT_MAX_WORDS\n",
    "\n",
    "image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "\n",
    "#model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v4/mil.baseline'\n",
    "#model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v4/mil/epoch/model.ckpt-30.00-24600'\n",
    "model_dir = '/home/gezi/mount/temp/image-caption/ai-challenger/model.v5/mil.sum/'\n",
    "vocab_path = '/home/gezi/mount/temp/image-caption/ai-challenger/tfrecord/seq-basic/vocab.txt'\n",
    "valid_dir = '/home/gezi/mount/temp/image-caption/ai-challenger/tfrecord/seq-basic/valid'\n",
    "\n",
    "\n",
    "image_model_name = melt.get_imagenet_from_checkpoint(image_model_checkpoint_path).name\n",
    "image_model = None\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      feature_name='attention')\n",
    "  \n",
    "    \n",
    "print('image_model:', image_model)\n",
    "\n",
    "text2ids.init(vocab_path)\n",
    "vocab = text2ids.vocab\n",
    "\n",
    "predictor = SimPredictor(model_dir,  \n",
    "                         image_model=image_model,\n",
    "                         index=-1)\n",
    "\n",
    "text_strs = np.load(os.path.join(valid_dir, 'distinct_text_strs.npy'))\n",
    "img2text = np.load(os.path.join(valid_dir, 'img2text.npy')).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_file = '/home/gezi/mine/mount/temp/image-caption/ai-challenger/model.v5/case.txt'\n",
    "for line in open(case_file):\n",
    "  image_name = line.strip().split()[0]\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  IMAGE_SIZE = (14, 10)\n",
    "  #plt.subplot(1, 1, 1)  \n",
    "  plt.figure(figsize=IMAGE_SIZE)\n",
    "  image_show(image_path)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "      continue\n",
    "  image = melt.read_image(image_path)\n",
    "\n",
    "  scores, word_ids = predictor.top_words([image], 200)\n",
    "  scores = scores[0]\n",
    "  word_ids = word_ids[0]\n",
    "  print('topwords of image ', image_name)\n",
    "  i = 0\n",
    "  for word_id, score in zip(word_ids, scores):\n",
    "    print(i, vocab.key(int(word_id)), score, end='|')\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_file like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg: ')\n",
    "  image_name = image_name.strip().replace('file://', '')\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "      continue\n",
    "        \n",
    "  # Size, in inches, of the output images.\n",
    "  IMAGE_SIZE = (14, 10)\n",
    "  #plt.subplot(1, 1, 1)  \n",
    "  plt.figure(figsize=IMAGE_SIZE)\n",
    "  image_show(image_path)\n",
    "\n",
    "#   try:\n",
    "#     hits = img2text[image_name]\n",
    "#     texts = [text_strs[hit] for hit in hits]\n",
    "#     for text in texts:\n",
    "#       word_ids = text2ids.text2ids(text)\n",
    "#       seg_text = text2ids.ids2text(word_ids, print_end=False)\n",
    "#       print('label:', text, seg_text)\n",
    "#       words_importance = predictor.words_importance([word_ids])\n",
    "#       words_importance = words_importance[0]\n",
    "#       for i in range(len(word_ids)):\n",
    "#         if word_ids[i] == 0:\n",
    "#           break \n",
    "#       print()\n",
    "#   except Exception:\n",
    "#     print(traceback.format_exc(), file=sys.stderr)    \n",
    "#     pass\n",
    "\n",
    "  image = melt.read_image(image_path)\n",
    "  scores, word_ids = predictor.top_words([image], 200)\n",
    "  scores = scores[0]\n",
    "  word_ids = word_ids[0]\n",
    "  print('topwords of image:')\n",
    "  i = 0\n",
    "  for word_id, score in zip(word_ids, scores):\n",
    "    print(i, vocab.key(int(word_id)), score, end='|')\n",
    "    i += 1\n",
    "\n",
    "  while True:\n",
    "    text = raw_input('text(q for exit): ')\n",
    "    if text is 'q' or not text.strip():\n",
    "      break\n",
    "    text = text.replace(' ', '')\n",
    "    print(text2ids.text2segtext(text))\n",
    "    print('sim:', predictor.predict([image], [text2ids.text2ids(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
