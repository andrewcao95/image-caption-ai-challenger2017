{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.4.0-rc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n",
      "checkpoint /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt model_name InceptionResnetV2 height 299 width 299\n",
      "build graph for final one feature\n",
      "preprocessing_fn net_name inception_resnet_v2 height 299 width 299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"Flatten/flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "build graph for attention features\n",
      "preprocessing_fn net_name inception_resnet_v2 height 299 width 299\n",
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"Flatten_1/flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt\n",
      "image_model <melt.image.image_model.ImageModel object at 0x7f4eee2436d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restore image var from InceptionResnetV2 /home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt duration: 12.8497669697\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('model_dir', '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/', '')\n",
    "  \n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "#debug\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "\n",
    "#model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v4/showattentell.coverage.keywords/'\n",
    "model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v4/showattentell.keywords.luong.batch32/'\n",
    "FLAGS.model_dir = model_dir\n",
    "\n",
    "image_model_name = melt.image.get_imagenet_from_checkpoint(image_model_checkpoint_path).name\n",
    "FLAGS.image_model_name = image_model_name\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, feature_name='attention')\n",
    "else:\n",
    "  image_model = None\n",
    "print('image_model', image_model)\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'coverage' in model_dir:\n",
    "FLAGS.coverage_attention_wrapper = True\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "FLAGS.showtell_encode_scope = 'encode'\n",
    "FLAGS.showtell_decode_scope = 'decode'\n",
    "FLAGS.image_endpoint_feature_name = 'attention'\n",
    "FLAGS.image_checkpoint_file = image_model_checkpoint_path \n",
    "FLAGS.pre_calc_image_feature = 1 \n",
    "FLAGS.finetune_image_model = True \n",
    "FLAGS.image_features_batch_norm = True \n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.alignment_history = True\n",
    "\n",
    "FLAGS.image_attention_size = FLAGS.image_attention_size or melt.image.get_num_features(FLAGS.image_model_name)\n",
    "FLAGS.image_feature_len = FLAGS.image_feature_len or melt.image.get_feature_dim(FLAGS.image_model_name) * FLAGS.image_attention_size\n",
    "\n",
    "beam_size = 100\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "rnn decoder gen only mode\n",
      "use melt.seq2seq.CoverageBahdanauAttention\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/image-caption/ai-challenger/model.v4/showattentell.keywords.luong.batch32/model.ckpt-0.46-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restore ok: /home/gezi/new/temp/image-caption/ai-challenger/model.v4/showattentell.keywords.luong.batch32/model.ckpt-0.46-3000\n",
      "load model ok /home/gezi/new/temp/image-caption/ai-challenger/model.v4/showattentell.keywords.luong.batch32/model.ckpt-0.46-3000 duration: 0.985901117325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f4f757089d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "    predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                beam_size=beam_size,\n",
    "                                length_normalization_factor=length_normalization_factor,\n",
    "                                logprobs_history=True,\n",
    "                                alignment_history=True)  \n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predict(image_path, predictor):\n",
    "  timer = gezi.Timer('beam search using time')\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    #attention model gen features only\n",
    "    feature = image_model.gen_features(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]    \n",
    "  #texts_list, scores_list = predictor.predict_text(feature)\n",
    "  #timer.print()\n",
    "  logprobs_history = None \n",
    "  alignment_history = None\n",
    "\n",
    "  l = predictor.predict_text(feature)\n",
    "  timer.print()\n",
    "  texts_list, scores_list= l[0], l[1]\n",
    "  try:\n",
    "    logprobs_history = l[2]\n",
    "    alignment_history = l[3]\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "  #print(alignment_history)\n",
    "\n",
    "  texts = texts_list[0]\n",
    "  scores = scores_list[0]\n",
    "  if logprobs_history is not None:\n",
    "    logprobs = logprobs_history[0]\n",
    "  else:\n",
    "    logprobs = [None] * len(texts)\n",
    "  if alignment_history is not None:\n",
    "    alignments = alignment_history[0]\n",
    "  else:\n",
    "    alignments = [None] * len(texts)\n",
    "    \n",
    "  logprob = None \n",
    "  alignment = None \n",
    "    \n",
    "  for text, score, logprob, alignment in zip(texts, scores, logprobs, alignments):\n",
    "    print('align shape', alignment.shape)\n",
    "    print(ids2text.ids2text(text), score)\n",
    "    print(text, len(text))\n",
    "    if logprob is not None:\n",
    "      print(map(math.exp, logprob))\n",
    "    #if alignment is not None:\n",
    "    #  print(alignment)\n",
    "    #  print(alignment[10], alignment[11], alignment[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple_predict(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=0.25, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  texts, scores, logprobs_history, alignment_history = predictor.predict_text(feature)\n",
    "  for i, (text, score, logprob, alignment) in enumerate(zip(texts[0], scores[0], logprobs_history[0], alignment_history[0])):\n",
    "    print(ids2text.ids2text(text), score)\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = ids2text.ids2words(text) \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 3:  \n",
    "      print('probs', [math.exp(x) for x in logprob])\n",
    "      for j in range(len(words)):\n",
    "        #if i == 0:\n",
    "        #  print(i, j, words[j], alignment[j])\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(words[j].decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(logprob[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(alignment[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(alignment[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg: ')\n",
    "  image_name = image_name.strip().replace('file://', '')\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
