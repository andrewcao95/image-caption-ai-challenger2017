{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.2.0-rc0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "#import matplotlib.pyplot as plt \n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('model_dir', '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/', '')\n",
    "  \n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "#debug\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-20.0-341406'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.coverage.finetune/epoch/'\n",
    "\n",
    "\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name)\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'coverage' in model_dir:\n",
    "  FLAGS.coverage_attention_wrapper = 1\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "FLAGS.image_attention_size = 64 \n",
    "FLAGS.image_endpoint_feature_name = 'Conv2d_7b_1x1'\n",
    "FLAGS.image_model = 'InceptionResnetV2'\n",
    "FLAGS.image_checkpoint_file = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt' \n",
    "FLAGS.pre_calc_image_feature = 0 \n",
    "FLAGS.finetune_image_model = 1 \n",
    "FLAGS.image_features_batch_norm = 1 \n",
    "FLAGS.image_features_drop_out = 1\n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.image_feature_len = 1536 * 64\n",
    "\n",
    "beam_size = 10\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_option: luong\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "rnn decoder gen only mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"show_and_tell/main/main/Flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "---------- Tensor(\"show_and_tell/main/main_1/concat_2:0\", shape=(?, 1792), dtype=float32)\n",
      "---------- Tensor(\"show_and_tell/main/main_1/Reshape_1:0\", shape=(?, 30), dtype=int32) Tensor(\"show_and_tell/main/main_1/Gather:0\", shape=(?, 10, 30), dtype=int32) Tensor(\"show_and_tell/main/main_1/TopKV2:0\", shape=(?, 10), dtype=float32) 30\n",
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000\n",
      "restore ok: /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load model ok /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000 duration: 7.60149407387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x94d7390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "  \n",
    "    beam_text, beam_text_score = predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                                        beam_size=beam_size,\n",
    "                                                        length_normalization_factor=length_normalization_factor)  \n",
    "    predictor.beam_text, predictor.beam_text_score = beam_text, beam_text_score\n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(image_path, predictor):\n",
    "  timer = gezi.Timer('beam search using time')\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    #attention model gen features only\n",
    "    feature = image_model.gen_features(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]    \n",
    "\n",
    "  texts_list, scores_list = predictor.predict_text(feature)\n",
    "  texts = texts_list[0]\n",
    "  scores = scores_list[0]\n",
    "  print(texts[0], len(texts[0]))\n",
    "  for text, score in zip(texts, scores):\n",
    "    print(ids2text.ids2text(text), score)\n",
    "  timer.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 748   21   19    3   10   44   18    3 1876    1   14    9    9    9    9\n",
      "    9    9    9    9    9    9    9    9    9    9    9    9    9    9    9] 30\n",
      "田地 里 站 着 一个 双手 拿 着 渔网 的 男人 </S> 0.0243456\n",
      "田地 里 站 着 一个 右手 拿 着 渔网 的 男人 </S> 0.0174184\n",
      "宽敞 的 田地 里 站 着 一位 双手 拿 着 渔网 的 男士 </S> 0.0140581\n",
      "宽敞 的 田地 里 站 着 一位 双手 拿 着 网兜 的 男士 </S> 0.0139881\n",
      "宽阔 的 田地 里 站 着 一个 右手 拿 着 渔网 的 男人 </S> 0.013862\n",
      "宽阔 的 田地 里 站 着 一个 双手 拿 着 渔网 的 男人 </S> 0.012865\n",
      "田地 里 站 着 一个 右手 拿 着 工具 的 男人 </S> 0.0109911\n",
      "一个 双手 拿 着 渔网 的 男人 站 在 池塘 里 </S> 0.0102351\n",
      "一个 双手 拿 着 渔网 的 男人 站 在 池塘 边 </S> 0.00838055\n",
      "一个 双手 拿 着 渔网 的 男人 站 在 河边 的 石头 上 </S> 0.00826508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beam search using time duration: 1.67791080475\n"
     ]
    }
   ],
   "source": [
    "predict(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg:')\n",
    "  image_name = image_name.strip()\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
