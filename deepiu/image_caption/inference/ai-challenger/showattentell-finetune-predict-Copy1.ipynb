{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.4.0-rc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('model_dir', '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/', '')\n",
    "  \n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "#debug\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-20.0-341406'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/'\n",
    "FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.coverage.finetune/'\n",
    "\n",
    "\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name)\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coverage' in model_dir:\n",
    "  FLAGS.coverage_attention_wrapper = True\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "FLAGS.image_attention_size = 64 \n",
    "FLAGS.image_endpoint_feature_name = 'Conv2d_7b_1x1'\n",
    "FLAGS.image_model = 'InceptionResnetV2'\n",
    "FLAGS.image_checkpoint_file = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt' \n",
    "FLAGS.pre_calc_image_feature = 0 \n",
    "FLAGS.finetune_image_model = True \n",
    "FLAGS.image_features_batch_norm = True \n",
    "FLAGS.image_features_drop_out = True\n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.image_feature_len = 1536 * 64\n",
    "FLAGS.alignment_history = True\n",
    "\n",
    "beam_size = 10\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "rnn decoder gen only mode\n",
      "preprocessing_fn net_name inception_resnet_v2 height None width None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-339ee760cd24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                 \u001b[0mlength_normalization_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_normalization_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0mlogprobs_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                 alignment_history=True)  \n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell_predictor.pyc\u001b[0m in \u001b[0;36minit_predict_text\u001b[0;34m(self, decode_method, beam_size, convert_unk, length_normalization_factor, max_words, logprobs_history, alignment_history)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mlogprobs_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogprobs_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       alignment_history=alignment_history)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecode_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSeqDecodeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell_predictor.pyc\u001b[0m in \u001b[0;36mbuild_predict_text_graph\u001b[0;34m(self, image, decode_method, beam_size, convert_unk, length_normalization_factor, max_words, logprobs_history, alignment_history)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtell_encode_scope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0mattention_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtell_decode_scope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell_predictor.pyc\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;31m#make different name compare to shown_and_tell.encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mattention_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_as_init_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0;31m#for im2txt one more step at first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell.pyc\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image_feature)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_process_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0mimage_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_process_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mimage_feature_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_feature_len\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mIMAGE_FEATURE_LEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/util/melt/image/image_processing.pyc\u001b[0m in \u001b[0;36mconstruct_fn\u001b[0;34m(encoded_image, height, width, trainable, is_training, resize_height, resize_width, random_crop, distort, slim_preprocessing, weight_decay, finetune_end_point, feature_name, num_classes, image_format, reuse)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessing_fn net_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_name_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'height'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         image = tf.map_fn(lambda img: preprocessing_fn(decode_image(img, image_format=image_format, dtype=tf.float32), height, width),\n\u001b[1;32m    522\u001b[0m                           encoded_image, dtype=tf.float32)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "    predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                beam_size=beam_size,\n",
    "                                length_normalization_factor=length_normalization_factor,\n",
    "                                logprobs_history=True,\n",
    "                                alignment_history=True)  \n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predict(image_path, predictor):\n",
    "  timer = gezi.Timer('beam search using time')\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    #attention model gen features only\n",
    "    feature = image_model.gen_features(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]    \n",
    "  #texts_list, scores_list = predictor.predict_text(feature)\n",
    "  #timer.print()\n",
    "  logprobs_history = None \n",
    "  alignment_history = None\n",
    "\n",
    "  l = predictor.predict_text(feature)\n",
    "  timer.print()\n",
    "  texts_list, scores_list= l[0], l[1]\n",
    "  try:\n",
    "    logprobs_history = l[2]\n",
    "    alignment_history = l[3]\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "  #print(alignment_history)\n",
    "\n",
    "  texts = texts_list[0]\n",
    "  scores = scores_list[0]\n",
    "  if logprobs_history is not None:\n",
    "    logprobs = logprobs_history[0]\n",
    "  else:\n",
    "    logprobs = [None] * len(texts)\n",
    "  if alignment_history is not None:\n",
    "    alignments = alignment_history[0]\n",
    "  else:\n",
    "    alignments = [None] * len(texts)\n",
    "    \n",
    "  logprob = None \n",
    "  alignment = None \n",
    "    \n",
    "  for text, score, logprob, alignment in zip(texts, scores, logprobs, alignments):\n",
    "    print('align shape', alignment.shape)\n",
    "    print(ids2text.ids2text(text), score)\n",
    "    print(text, len(text))\n",
    "    if logprob is not None:\n",
    "      print(map(math.exp, logprob))\n",
    "    #if alignment is not None:\n",
    "    #  print(alignment)\n",
    "    #  print(alignment[10], alignment[11], alignment[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple_predict(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=0.25, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  texts, scores, logprobs_history, alignment_history = predictor.predict_text(feature)\n",
    "  for i, (text, score, logprob, alignment) in enumerate(zip(texts[0], scores[0], logprobs_history[0], alignment_history[0])):\n",
    "    print(ids2text.ids2text(text), score)\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = ids2text.ids2words(text) \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 1:  \n",
    "      for j in range(len(words)):\n",
    "        #if i == 0:\n",
    "        #  print(i, j, words[j], alignment[j])\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(words[j].decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(logprob[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(alignment[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(alignment[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg: ')\n",
    "  image_name = image_name.strip()\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
