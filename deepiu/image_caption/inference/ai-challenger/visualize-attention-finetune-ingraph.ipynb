{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.2.0-rc0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "#import matplotlib.pyplot as plt \n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000'\n",
    "#model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/exp/'\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name)\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'coverage' in model_dir:\n",
    "  FLAGS.coverage_attention_wrapper = True\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "FLAGS.image_attention_size = 64 \n",
    "FLAGS.image_endpoint_feature_name = 'Conv2d_7b_1x1'\n",
    "FLAGS.image_model = 'InceptionResnetV2'\n",
    "FLAGS.image_checkpoint_file = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt' \n",
    "FLAGS.pre_calc_image_feature = 0 \n",
    "FLAGS.finetune_image_model = True \n",
    "FLAGS.image_features_batch_norm = True \n",
    "FLAGS.image_features_drop_out = True\n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.image_feature_len = 1536 * 64\n",
    "FLAGS.alignment_history = True\n",
    "\n",
    "beam_size = 10\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_option: luong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "rnn decoder gen only mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"show_and_tell/main/main/Flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000\n"
     ]
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "    predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                beam_size=beam_size,\n",
    "                                length_normalization_factor=length_normalization_factor,\n",
    "                                logprobs_history=True,\n",
    "                                alignment_history=True)  \n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=0.25, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  texts, scores, logprobs_history, alignment_history = predictor.predict_text(feature)\n",
    "  for i, (text, score, logprob, alignment) in enumerate(zip(texts[0], scores[0], logprobs_history[0], alignment_history[0])):\n",
    "    print(ids2text.ids2text(text), math.exp(score))\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = ids2text.ids2words(text) \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 1:  \n",
    "      for j in range(len(words)):\n",
    "        if i == 0:\n",
    "          print(i, j, words[j], alignment[j])\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(ids2text.vocab.key(words[j]).decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(logprob[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(alignment[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(alignment[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import glob \n",
    "#for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "#    image_show(img)\n",
    "#    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg:')\n",
    "  image_name = image_name.strip()\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
