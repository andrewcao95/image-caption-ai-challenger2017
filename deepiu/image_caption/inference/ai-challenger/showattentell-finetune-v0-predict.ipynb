{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 10148 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('model_dir', '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/', '')\n",
    "  \n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "#debug\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/new/temp/image-caption/ai-challenger/tfrecord/seq-basic-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000'\n",
    "FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/'\n",
    "\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name)\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coverage' in model_dir:\n",
    "  FLAGS.coverage_attention_wrapper = True\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "#FLAGS.showtell_encode_scope = 'encode'\n",
    "#FLAGS.showtell_decode_scope = 'decode'\n",
    "FLAGS.image_attention_size = 64 \n",
    "FLAGS.image_endpoint_feature_name = 'Conv2d_7b_1x1'\n",
    "FLAGS.image_model = 'InceptionResnetV2'\n",
    "FLAGS.image_checkpoint_file = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt' \n",
    "FLAGS.pre_calc_image_feature = 0 \n",
    "FLAGS.finetune_image_model = True \n",
    "FLAGS.image_features_batch_norm = True \n",
    "FLAGS.image_features_drop_out = True\n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.image_feature_len = 1536 * 64\n",
    "FLAGS.alignment_history = True\n",
    "\n",
    "beam_size = 10\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "vocab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-339ee760cd24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0malgos_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n\u001b[1;32m      9\u001b[0m                                 \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/util/algos_factory.pyc\u001b[0m in \u001b[0;36mgen_predictor\u001b[0;34m(algo, reuse)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gen_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/util/algos_factory.pyc\u001b[0m in \u001b[0;36m_gen_predictor\u001b[0;34m(algo)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecitor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecitor_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gen_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell_predictor.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmelt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredictorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mShowAndTell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_calc_image_feature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/mine/hasky/deepiu/image_caption/algos/show_and_tell.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_training, is_predict)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_restore_embedding_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmelt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor_level\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mmelt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: vocab"
     ]
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "    predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                beam_size=beam_size,\n",
    "                                length_normalization_factor=length_normalization_factor,\n",
    "                                logprobs_history=True,\n",
    "                                alignment_history=True)  \n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predict(image_path, predictor):\n",
    "  timer = gezi.Timer('beam search using time')\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    #attention model gen features only\n",
    "    feature = image_model.gen_features(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]    \n",
    "  #texts_list, scores_list = predictor.predict_text(feature)\n",
    "  #timer.print()\n",
    "  logprobs_history = None \n",
    "  alignment_history = None\n",
    "\n",
    "  l = predictor.predict_text(feature)\n",
    "  timer.print()\n",
    "  texts_list, scores_list= l[0], l[1]\n",
    "  try:\n",
    "    logprobs_history = l[2]\n",
    "    alignment_history = l[3]\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "  #print(alignment_history)\n",
    "\n",
    "  texts = texts_list[0]\n",
    "  scores = scores_list[0]\n",
    "  if logprobs_history is not None:\n",
    "    logprobs = logprobs_history[0]\n",
    "  else:\n",
    "    logprobs = [None] * len(texts)\n",
    "  if alignment_history is not None:\n",
    "    alignments = alignment_history[0]\n",
    "  else:\n",
    "    alignments = [None] * len(texts)\n",
    "    \n",
    "  logprob = None \n",
    "  alignment = None \n",
    "    \n",
    "  for text, score, logprob, alignment in zip(texts, scores, logprobs, alignments):\n",
    "    print('align shape', alignment.shape)\n",
    "    print(ids2text.ids2text(text), score)\n",
    "    print(text, len(text))\n",
    "    if logprob is not None:\n",
    "      print(map(math.exp, logprob))\n",
    "    #if alignment is not None:\n",
    "    #  print(alignment)\n",
    "    #  print(alignment[10], alignment[11], alignment[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple_predict(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=0.25, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  texts, scores, logprobs_history, alignment_history = predictor.predict_text(feature)\n",
    "  for i, (text, score, logprob, alignment) in enumerate(zip(texts[0], scores[0], logprobs_history[0], alignment_history[0])):\n",
    "    print(ids2text.ids2text(text), score)\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = ids2text.ids2words(text) \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 10:  \n",
    "      for j in range(len(words)):\n",
    "        #if i == 0:\n",
    "        #  print(i, j, words[j], alignment[j])\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(words[j].decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(logprob[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(alignment[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(alignment[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg: ')\n",
    "  image_name = image_name.strip().replace('file://', '')\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
