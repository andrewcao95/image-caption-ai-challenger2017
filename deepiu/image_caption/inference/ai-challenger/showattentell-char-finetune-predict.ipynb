{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /home/gezi/temp/image-caption/ai-challenger/tfrecord/char-finetune/vocab.txt\n",
      "INFO:tensorflow:Created vocabulary with 2443 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENCODE_UNK 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.transform\n",
    "from scipy import ndimage\n",
    "import scipy.misc\n",
    "\n",
    "def image_show(image_path):\n",
    "  imshow(np.asarray(Image.open(image_path, 'r')))\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "#flags.DEFINE_string('model_dir', '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/', '')\n",
    "  \n",
    "import sys, os, math\n",
    "import gezi, melt\n",
    "import numpy as np\n",
    "\n",
    "from deepiu.util import algos_factory\n",
    "from deepiu.seq2seq.rnn_decoder import SeqDecodeMethod\n",
    "\n",
    "#debug\n",
    "from deepiu.util import text2ids\n",
    "\n",
    "TEXT_MAX_WORDS = 100    \n",
    "decode_max_words = 20\n",
    "\n",
    "\n",
    "from deepiu.util import ids2text\n",
    "vocab_path = '/home/gezi/temp/image-caption/ai-challenger/tfrecord/char-finetune/vocab.txt'\n",
    "ids2text.init(vocab_path)\n",
    "\n",
    "image_dir = image_dir = '/home/gezi/data2/data/ai_challenger/image_caption/pic/'\n",
    "image_file = '6275b5349168ac3fab6a493c509301d023cf39d3.jpg'\n",
    "image_path = os.path.join(image_dir, image_file)\n",
    "image_model_checkpoint_path = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt'\n",
    "image_model_name='InceptionResnetV2'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-25.3-516000'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.finetune/epoch/model.ckpt-20.0-341406'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v3/showattentell.finetune/'\n",
    "FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model.v3/showattentell.char.finetune/'\n",
    "#FLAGS.model_dir = model_dir = '/home/gezi/new/temp/image-caption/ai-challenger/model/showattentell.coverage.finetune/epoch/'\n",
    "\n",
    "\n",
    "if not melt.varname_in_checkpoint(image_model_name, model_dir):\n",
    "  image_model = melt.image.ImageModel(image_model_checkpoint_path, \n",
    "                                      model_name=image_model_name)\n",
    "else:\n",
    "  image_model = None\n",
    "\n",
    "import libpinyin\n",
    "pinyin = libpinyin.Pinyin()\n",
    "pinyin.Load('./data/pinyin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'coverage' in model_dir:\n",
    "  FLAGS.coverage_attention_wrapper = True\n",
    "\n",
    "FLAGS.image_encoder = 'Rnn'\n",
    "FLAGS.showtell_encode_scope = 'encode'\n",
    "FLAGS.showtell_decode_scope = 'decode'\n",
    "FLAGS.image_attention_size = 64 \n",
    "FLAGS.image_endpoint_feature_name = 'Conv2d_7b_1x1'\n",
    "FLAGS.image_model = 'InceptionResnetV2'\n",
    "FLAGS.image_checkpoint_file = '/home/gezi/data/image_model_check_point/inception_resnet_v2_2016_08_30.ckpt' \n",
    "FLAGS.pre_calc_image_feature = 0 \n",
    "FLAGS.finetune_image_model = True \n",
    "FLAGS.image_features_batch_norm = True \n",
    "FLAGS.image_features_drop_out = True\n",
    "FLAGS.emb_dim = 512 \n",
    "FLAGS.rnn_hidden_size = 512 \n",
    "FLAGS.image_feature_len = 1536 * 64\n",
    "FLAGS.alignment_history = True\n",
    "\n",
    "FLAGS.decoder_max_words = 60\n",
    "\n",
    "beam_size = 10\n",
    "length_normalization_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_option: luong\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "cell: <class 'tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell'>\n",
      "rnn decoder gen only mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_model will get feature_name Conv2d_7b_1x1\n",
      "image_feature: Tensor(\"show_and_tell/main/encode/Flatten/Reshape:0\", shape=(?, 98304), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /home/gezi/new/temp/image-caption/ai-challenger/model.v3/showattentell.char.finetune/model.ckpt-20.7-92000\n",
      "restore ok: /home/gezi/new/temp/image-caption/ai-challenger/model.v3/showattentell.char.finetune/model.ckpt-20.7-92000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load model ok /home/gezi/new/temp/image-caption/ai-challenger/model.v3/showattentell.char.finetune/model.ckpt-20.7-92000 duration: 23.3698370457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f54a000bf50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = 'show_and_tell'\n",
    "global_scope = algo\n",
    "main_scope = 'main'\n",
    "melt.apps.image_processing.init()\n",
    "with tf.variable_scope(global_scope):\n",
    "  with tf.variable_scope(main_scope):\n",
    "    predictor =  algos_factory.gen_predictor(algo)\n",
    "    predictor.init_predict_text(decode_method=SeqDecodeMethod.ingraph_beam, \n",
    "                                beam_size=beam_size,\n",
    "                                length_normalization_factor=length_normalization_factor,\n",
    "                                logprobs_history=True,\n",
    "                                alignment_history=True)  \n",
    "\n",
    "predictor.load(FLAGS.model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predict(image_path, predictor):\n",
    "  timer = gezi.Timer('beam search using time')\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    #attention model gen features only\n",
    "    feature = image_model.gen_features(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]    \n",
    "  #texts_list, scores_list = predictor.predict_text(feature)\n",
    "  #timer.print()\n",
    "  logprobs_history = None \n",
    "  alignment_history = None\n",
    "\n",
    "  l = predictor.predict_text(feature)\n",
    "  timer.print()\n",
    "  texts_list, scores_list= l[0], l[1]\n",
    "  try:\n",
    "    logprobs_history = l[2]\n",
    "    alignment_history = l[3]\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "  #print(alignment_history)\n",
    "\n",
    "  texts = texts_list[0]\n",
    "  scores = scores_list[0]\n",
    "  if logprobs_history is not None:\n",
    "    logprobs = logprobs_history[0]\n",
    "  else:\n",
    "    logprobs = [None] * len(texts)\n",
    "  if alignment_history is not None:\n",
    "    alignments = alignment_history[0]\n",
    "  else:\n",
    "    alignments = [None] * len(texts)\n",
    "    \n",
    "  logprob = None \n",
    "  alignment = None \n",
    "    \n",
    "  for text, score, logprob, alignment in zip(texts, scores, logprobs, alignments):\n",
    "    print('align shape', alignment.shape)\n",
    "    print(ids2text.ids2text(text), score)\n",
    "    print(text, len(text))\n",
    "    if logprob is not None:\n",
    "      #print(map(math.exp, logprob))\n",
    "      print('|'.join(['%s %.2f'%(ids2text.vocab.key(int(t)), math.exp(logp)) for t, logp in zip(text, logprob)]))\n",
    "    #if alignment is not None:\n",
    "    #  print(alignment)\n",
    "    #  print(alignment[10], alignment[11], alignment[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple_predict(image_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, predictor, length_normalization_factor=0.25, num_show=1):\n",
    "  img = melt.read_image(image_path)\n",
    "  if image_model:\n",
    "    feature = image_model.gen_feature(img) if image_model is not None else img\n",
    "  else:\n",
    "    feature = [img]\n",
    "\n",
    "  timer = gezi.Timer()\n",
    "  texts, scores, logprobs_history, alignment_history = predictor.predict_text(feature)\n",
    "  for i, (text, score, logprob, alignment) in enumerate(zip(texts[0], scores[0], logprobs_history[0], alignment_history[0])):\n",
    "    print(ids2text.ids2text(text), score)\n",
    "\n",
    "    # Plot images with attention weights\n",
    "    words = ids2text.ids2words(text) \n",
    "    img = ndimage.imread(image_path)\n",
    "    \n",
    "    num_features = melt.image.get_num_features(image_model_name)\n",
    "    dim = int(np.sqrt(num_features))\n",
    "    #print('dim:', dim)\n",
    "\n",
    "    n_words = len(words)\n",
    "    n_words += 1 #for ori image\n",
    "    w = np.round(np.sqrt(n_words))\n",
    "    h = np.ceil(np.float32(n_words) / w)\n",
    "    \n",
    "    #print(n_words, w, h)\n",
    "            \n",
    "    plt.subplot(w, h, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    #img = scipy.misc.imresize(img, (dim, dim))  \n",
    "\n",
    "    #smooth = True  #TODO smooth = Ture seems not work not back ground pic\n",
    "    smooth = False\n",
    "    if i < 10:  \n",
    "      print('probs', [math.exp(x) for x in logprob])\n",
    "      for j in range(len(words)):\n",
    "        #if i == 0:\n",
    "        #  print(i, j, words[j], alignment[j])\n",
    "        plt.subplot(w, h, j + 2)\n",
    "        lab = pinyin.Convert(words[j].decode('utf8').encode('gbk'))\n",
    "        lab += '(%0.2f)'%math.exp(logprob[j])\n",
    "        plt.text(0, 1, lab, backgroundcolor='white', fontsize=10)\n",
    "        plt.text(0, 1, lab, color='black', fontsize=10)\n",
    "        plt.imshow(img)\n",
    "        if smooth:\n",
    "          alpha_img = skimage.transform.pyramid_expand(alignment[j].reshape(dim, dim), upscale=16, sigma=20)\n",
    "        else:\n",
    "          alpha_img = skimage.transform.resize(alignment[j].reshape(dim, dim), [img.shape[0], img.shape[1]])\n",
    "        plt.imshow(alpha_img, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "      plt.show()\n",
    "      #plt.savefig('test%d.pdf'%i)\n",
    "\n",
    "    print('beam search using time(ms):', timer.elapsed_ms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  image_name = raw_input('image_name like 6275b5349168ac3fab6a493c509301d023cf39d3.jpg: ')\n",
    "  image_name = image_name.strip()\n",
    "  if image_name == 'q':\n",
    "    break\n",
    "  if not image_name.endswith('.jpg'):\n",
    "    image_name += '.jpg'\n",
    "\n",
    "  image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "  if not os.path.exists(image_path):\n",
    "    print('path not exists:%s'%image_path)\n",
    "    image_path = image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "  plt.subplot(1, 1, 1)\n",
    "  image_show(image_path)\n",
    "  predict(image_path, predictor)\n",
    "  #predict(image_path, predictor2, gen_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "for img in glob.glob('/home/gezi/new2/data/ai_challenger/image_caption/test_pic/*.jpg'):\n",
    "    image_show(img)\n",
    "    predict(img, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
